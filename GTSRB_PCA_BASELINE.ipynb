{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/christoph/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/home/christoph/Desktop/ma/data/gtsrb/\"\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIMS = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(ROOT_DIR + \"Train.csv\")\n",
    "valid_csv = pd.read_csv(ROOT_DIR + \"Test.csv\")\n",
    "\n",
    "train_files = train_csv[[\"Path\", \"ClassId\"]]\n",
    "valid_files = valid_csv[[\"Path\", \"ClassId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tv.transforms.Compose([tv.transforms.Resize((IMG_SIZE, IMG_SIZE)), tv.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.join(dirpath,filename) for dirpath, _, filenames in os.walk(ROOT_DIR + \"Train/\") for filename in filenames if filename.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9209/9209 [00:03<00:00, 2882.12it/s]\n"
     ]
    }
   ],
   "source": [
    "file_arr = []\n",
    "for i in tqdm(range(len(filenames)-30000)):\n",
    "    if i%10 == 0:\n",
    "        image = Image.open(filenames[i])\n",
    "        tens = tfms(image)\n",
    "        conv_filename = filenames[i].split(\"gtsrb/\")[-1]\n",
    "        class_id = int(train_files[train_files[\"Path\"] == conv_filename][\"ClassId\"].astype(int))\n",
    "        tens_id_arr = [tens, class_id]\n",
    "        file_arr.append(tens_id_arr)\n",
    "    \n",
    "random.shuffle(file_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDataset(Dataset):\n",
    "    def __init__(self, files, transform=None):\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        x = self.files[idx][0]\n",
    "        label = self.files[idx][1]\n",
    "            \n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = TSDataset(file_arr, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier architecture\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(20, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv3(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE architecture\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=1024, z_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        \n",
    "        self.signclass_embedding = nn.Embedding(43, 20)\n",
    "        \n",
    "        self.h2mu = nn.Linear(h_dim, z_dim)\n",
    "        self.h2sigma = nn.Linear(h_dim, z_dim)\n",
    "        self.z2h = nn.Linear(z_dim + 20, h_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.randn(*mu.size()).to(DEVICE)\n",
    "        z = mu + std * eps\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h, label):\n",
    "        mu = self.h2mu(h)\n",
    "        logvar = self.h2sigma(h)\n",
    "\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        return z, mu, logvar\n",
    "    \n",
    "    def extract_model(self):\n",
    "        return self.signclass_embedding, self.z2h, self.decoder\n",
    "        \n",
    "    def encode(self, x, label):\n",
    "        return self.bottleneck(self.encoder(x), label)[0]\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(self.z2h(z))\n",
    "    \n",
    "    def forward(self, x, label):\n",
    "        h = self.encoder(x)\n",
    "        z_small, mu, logvar = self.bottleneck(h, label)\n",
    "        \n",
    "        signclass = self.signclass_embedding(label.long())\n",
    "        signclass = signclass.squeeze(dim=1)\n",
    "        z_small_cat = torch.cat([z_small, signclass], dim=1)\n",
    "        z = self.z2h(z_small_cat)\n",
    "        return self.decoder(z), mu, logvar, z_small, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble architecture (combining cvae and classifier)\n",
    "\n",
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, embeddings, upscaler, decoder, classifier):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.upscaler = upscaler\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, z, label):\n",
    "        enc_label = self.embeddings(label.long())\n",
    "        enc_label = enc_label.squeeze(dim=1)\n",
    "        x = torch.cat((z, enc_label), dim=1)\n",
    "        x = self.upscaler(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def get_img(self, z, label):\n",
    "        enc_label = self.embeddings(label.long())\n",
    "        x = torch.cat((z, enc_label), dim=1)\n",
    "        x = self.upscaler(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models for classifier and cvae\n",
    "\n",
    "classifier = Classifier()\n",
    "classifier.eval()\n",
    "cvae = CVAE()\n",
    "\n",
    "classifier.load_state_dict(torch.load(\"gtsrb_classifier_50.pth\"))\n",
    "cvae.load_state_dict(torch.load(\"ccvae_32_signs_extract_50.pth\"))\n",
    "\n",
    "classifier.to(DEVICE)\n",
    "cvae.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cvae and classifier into ensemble\n",
    "\n",
    "embeddings, upscaler, decoder = cvae.extract_model()\n",
    "ensemble = Ensemble(embeddings, upscaler, decoder, classifier)\n",
    "ensemble.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = []\n",
    "for data, label in train_dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, label = data.cuda(), label.type(torch.FloatTensor).unsqueeze(dim=1).cuda()\n",
    "\n",
    "        recon_batch, mu, logvar, _, _ = cvae(data, label)  \n",
    "        to_np = mu.detach().cpu().numpy()\n",
    "        np_arr.append(to_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_tensors = np.vstack(np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/christoph/Desktop/gtsrb_32dim.npy', 'wb') as f:\n",
    "    a = np.save(f, stacked_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/christoph/Desktop/gtsrb_32dim.npy', 'rb') as f:\n",
    "    tensors = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-26036ba53f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \"\"\"\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"arpack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"randomized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                 \u001b[0mflip_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# compute the SVD on the thin matrix: (k + p) wide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mUhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'masked arrays are not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         raise ValueError(\n\u001b[0;32m--> 489\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    490\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christoph/anaconda3/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator PCA from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "with open('/home/christoph/Desktop/gtsrb_pca.pkl', 'rb') as f:\n",
    "    pca = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/christoph/Desktop/gtsrb_feats.npy', 'rb') as f:\n",
    "    embs = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [-1, -0.5, 0, 0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 64, 64]), torch.Size([128, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_class = 5\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "cvae_data, cvae_labels = next(iter(train_dataloader))\n",
    "cvae_data, cvae_labels = cvae_data.to(DEVICE), cvae_labels.to(DEVICE)\n",
    "cvae_labels = cvae_labels.unsqueeze(dim=1)\n",
    "cvae_data.shape, cvae_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_batch, mu, logvar, data, z = cvae(cvae_data, cvae_labels)\n",
    "mu[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_1d(z_orig, label, ranges, dim):\n",
    "    noisy_data = []\n",
    "    probs = []\n",
    "    for step, value in enumerate(ranges):\n",
    "        noise = torch.zeros(1, 5).to(DEVICE)\n",
    "        noise[0, dim] = value\n",
    "        z_compressed = z_orig.unsqueeze(dim=0) + noise\n",
    "        \n",
    "        z_compressed = z_compressed.to(\"cpu\")\n",
    "        \n",
    "        z = pca.inverse_transform(z_compressed)\n",
    "        \n",
    "        z = torch.Tensor(z).to(DEVICE)\n",
    "\n",
    "        pred_logits = ensemble(z, label.unsqueeze(dim=0)) \n",
    "        loss = ce_loss(pred_logits, label)\n",
    "        norm_vals = abs(value)\n",
    "        loss_normed = loss*100/torch.exp(torch.Tensor([norm_vals]).to(DEVICE))\n",
    "        pred_probs = F.softmax(pred_logits)\n",
    "\n",
    "        pred = pred_probs.max(1, keepdim=True)[1][0]\n",
    "        prob = pred_probs.max(1, keepdim=True)[0]\n",
    "\n",
    "        img = ensemble.get_img(z, label)\n",
    "        img = img.squeeze(dim=0)\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "\n",
    "        noisy_data.append(img)\n",
    "        probs.append(prob.item())\n",
    "            \n",
    "    return [noisy_data, np.round(probs, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.Tensor(embs[0]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christoph/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[array([[[0.33204687, 0.30579707, 0.28167385],\n",
       "          [0.32451499, 0.29457518, 0.27178654],\n",
       "          [0.32497332, 0.28840703, 0.2652441 ],\n",
       "          ...,\n",
       "          [0.31627873, 0.28804445, 0.26761037],\n",
       "          [0.31408957, 0.2899756 , 0.27095136],\n",
       "          [0.32452178, 0.30080447, 0.28263074]],\n",
       "  \n",
       "         [[0.3270485 , 0.2968242 , 0.27198952],\n",
       "          [0.31940758, 0.283434  , 0.25620678],\n",
       "          [0.31680176, 0.27669784, 0.25042242],\n",
       "          ...,\n",
       "          [0.31781214, 0.2849842 , 0.26397783],\n",
       "          [0.30825415, 0.28324622, 0.26294142],\n",
       "          [0.32277256, 0.3009061 , 0.27854   ]],\n",
       "  \n",
       "         [[0.32860142, 0.29492706, 0.26437327],\n",
       "          [0.3193335 , 0.28201306, 0.2483052 ],\n",
       "          [0.3138591 , 0.27738357, 0.24601097],\n",
       "          ...,\n",
       "          [0.32049182, 0.29056373, 0.26576623],\n",
       "          [0.30802056, 0.28264305, 0.25519663],\n",
       "          [0.3169396 , 0.291118  , 0.2653725 ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.21054415, 0.19001812, 0.18106855],\n",
       "          [0.20094584, 0.1832926 , 0.17392927],\n",
       "          [0.19723769, 0.17917354, 0.17108773],\n",
       "          ...,\n",
       "          [0.2875744 , 0.24529597, 0.19588456],\n",
       "          [0.27931273, 0.23650774, 0.18991151],\n",
       "          [0.2673047 , 0.23222376, 0.19816238]],\n",
       "  \n",
       "         [[0.21137612, 0.1969995 , 0.19424172],\n",
       "          [0.19992742, 0.18413603, 0.18112062],\n",
       "          [0.19985995, 0.18490593, 0.1763001 ],\n",
       "          ...,\n",
       "          [0.27564108, 0.23126999, 0.19352227],\n",
       "          [0.2694851 , 0.23066033, 0.19754718],\n",
       "          [0.2655887 , 0.23232068, 0.20615591]],\n",
       "  \n",
       "         [[0.21747763, 0.20124426, 0.1957725 ],\n",
       "          [0.20905758, 0.19426514, 0.19124123],\n",
       "          [0.20310064, 0.18663259, 0.18638186],\n",
       "          ...,\n",
       "          [0.27564475, 0.23885895, 0.20559213],\n",
       "          [0.26855436, 0.23464307, 0.2066881 ],\n",
       "          [0.26704624, 0.23942836, 0.21429573]]], dtype=float32),\n",
       "  array([[[0.31764063, 0.29234433, 0.26917046],\n",
       "          [0.311436  , 0.2817842 , 0.2601304 ],\n",
       "          [0.31526503, 0.2777182 , 0.25436637],\n",
       "          ...,\n",
       "          [0.3008373 , 0.27442974, 0.2558422 ],\n",
       "          [0.29798126, 0.27538702, 0.25805876],\n",
       "          [0.30850625, 0.28635734, 0.2699294 ]],\n",
       "  \n",
       "         [[0.31178162, 0.28191662, 0.25785407],\n",
       "          [0.30639464, 0.2700052 , 0.24364792],\n",
       "          [0.3075881 , 0.2641005 , 0.23775406],\n",
       "          ...,\n",
       "          [0.30201593, 0.27050602, 0.25136045],\n",
       "          [0.2915828 , 0.26785684, 0.24922451],\n",
       "          [0.30660808, 0.28617913, 0.26535696]],\n",
       "  \n",
       "         [[0.3113287 , 0.277378  , 0.24789247],\n",
       "          [0.30444667, 0.26594648, 0.23317952],\n",
       "          [0.30041203, 0.26123333, 0.23039843],\n",
       "          ...,\n",
       "          [0.3019521 , 0.27383548, 0.25174245],\n",
       "          [0.28826484, 0.26462206, 0.23979734],\n",
       "          [0.29780194, 0.27377564, 0.25054237]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.20052901, 0.18073265, 0.1727842 ],\n",
       "          [0.19143294, 0.17451437, 0.16621612],\n",
       "          [0.18708359, 0.16966146, 0.16299815],\n",
       "          ...,\n",
       "          [0.27111214, 0.23012862, 0.18146674],\n",
       "          [0.26296648, 0.22148883, 0.17603162],\n",
       "          [0.25322327, 0.21917625, 0.18573341]],\n",
       "  \n",
       "         [[0.20059319, 0.18697847, 0.18514735],\n",
       "          [0.1892064 , 0.17426537, 0.17221121],\n",
       "          [0.18861069, 0.17454402, 0.16700427],\n",
       "          ...,\n",
       "          [0.25913814, 0.21585117, 0.17901397],\n",
       "          [0.25378013, 0.21616812, 0.18411693],\n",
       "          [0.2517705 , 0.21953045, 0.19414838]],\n",
       "  \n",
       "         [[0.20670268, 0.19122753, 0.18656582],\n",
       "          [0.19830184, 0.18428056, 0.18212529],\n",
       "          [0.1918954 , 0.17615218, 0.17684843],\n",
       "          ...,\n",
       "          [0.26158702, 0.22550349, 0.19261803],\n",
       "          [0.25511402, 0.22200993, 0.19476695],\n",
       "          [0.25459132, 0.22772865, 0.20321299]]], dtype=float32),\n",
       "  array([[[0.3049897 , 0.2798618 , 0.25689512],\n",
       "          [0.30012816, 0.2699602 , 0.24874161],\n",
       "          [0.30745533, 0.26820934, 0.24403302],\n",
       "          ...,\n",
       "          [0.28565174, 0.26077232, 0.24372141],\n",
       "          [0.28283733, 0.2614225 , 0.24543612],\n",
       "          [0.29346442, 0.27255535, 0.25749466]],\n",
       "  \n",
       "         [[0.29823402, 0.26813385, 0.24413252],\n",
       "          [0.29499757, 0.25755343, 0.23138888],\n",
       "          [0.30037025, 0.2530411 , 0.22601813],\n",
       "          ...,\n",
       "          [0.28669748, 0.25634867, 0.23864694],\n",
       "          [0.2762211 , 0.2534188 , 0.23614152],\n",
       "          [0.29161993, 0.27229255, 0.25266913]],\n",
       "  \n",
       "         [[0.2956622 , 0.26102415, 0.23205926],\n",
       "          [0.290933  , 0.2508923 , 0.2184715 ],\n",
       "          [0.28852922, 0.24686724, 0.2162783 ],\n",
       "          ...,\n",
       "          [0.284699  , 0.25835392, 0.23806109],\n",
       "          [0.270658  , 0.24845766, 0.22551583],\n",
       "          [0.2804956 , 0.2579501 , 0.23651315]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.19009535, 0.17131595, 0.16451582],\n",
       "          [0.1815419 , 0.16567485, 0.15856111],\n",
       "          [0.17648378, 0.16017248, 0.15506291],\n",
       "          ...,\n",
       "          [0.25137863, 0.21246563, 0.16565993],\n",
       "          [0.2438071 , 0.20431364, 0.16092195],\n",
       "          [0.23687811, 0.20440684, 0.17220378]],\n",
       "  \n",
       "         [[0.18938403, 0.17679834, 0.17601225],\n",
       "          [0.17806661, 0.16431783, 0.16331673],\n",
       "          [0.17713913, 0.16444796, 0.15816484],\n",
       "          ...,\n",
       "          [0.23993243, 0.19834237, 0.16311276],\n",
       "          [0.23567037, 0.19972117, 0.16930504],\n",
       "          [0.23606414, 0.20516622, 0.1809693 ]],\n",
       "  \n",
       "         [[0.19540913, 0.1809102 , 0.17717567],\n",
       "          [0.18695912, 0.17400122, 0.17284249],\n",
       "          [0.18027112, 0.1657081 , 0.16745606],\n",
       "          ...,\n",
       "          [0.24537978, 0.21045876, 0.17839849],\n",
       "          [0.23970865, 0.20773228, 0.18159188],\n",
       "          [0.24049236, 0.21466288, 0.19105424]]], dtype=float32),\n",
       "  array([[[0.29428458, 0.26814115, 0.24426852],\n",
       "          [0.29045972, 0.25862736, 0.23676889],\n",
       "          [0.29996967, 0.25842604, 0.23280442],\n",
       "          ...,\n",
       "          [0.2703138 , 0.2464334 , 0.2300696 ],\n",
       "          [0.2682604 , 0.24757823, 0.23217367],\n",
       "          [0.27928805, 0.2591103 , 0.24465585]],\n",
       "  \n",
       "         [[0.28655845, 0.2553494 , 0.23033811],\n",
       "          [0.28491187, 0.24559955, 0.21858467],\n",
       "          [0.2935467 , 0.24242124, 0.21406771],\n",
       "          ...,\n",
       "          [0.27133304, 0.24188995, 0.22469682],\n",
       "          [0.26137897, 0.23923378, 0.2225111 ],\n",
       "          [0.27742887, 0.2588191 , 0.23961638]],\n",
       "  \n",
       "         [[0.28183103, 0.24596071, 0.2166701 ],\n",
       "          [0.2785655 , 0.2366462 , 0.20365523],\n",
       "          [0.27733976, 0.23384647, 0.20300288],\n",
       "          ...,\n",
       "          [0.26889881, 0.24384241, 0.22395909],\n",
       "          [0.25495455, 0.23366393, 0.21117824],\n",
       "          [0.26524737, 0.24347863, 0.22247998]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.17808118, 0.16060969, 0.15518065],\n",
       "          [0.16999751, 0.15549791, 0.14976548],\n",
       "          [0.16415274, 0.14939456, 0.14607395],\n",
       "          ...,\n",
       "          [0.23119867, 0.19520968, 0.15116934],\n",
       "          [0.22415361, 0.18735105, 0.14671266],\n",
       "          [0.21917199, 0.18887766, 0.15864994]],\n",
       "  \n",
       "         [[0.17723797, 0.16581355, 0.16614057],\n",
       "          [0.16604403, 0.1536406 , 0.15377772],\n",
       "          [0.16472119, 0.15364918, 0.14875361],\n",
       "          ...,\n",
       "          [0.22056025, 0.18145868, 0.1483694 ],\n",
       "          [0.21722399, 0.18352146, 0.1550378 ],\n",
       "          [0.21928322, 0.1901536 , 0.16749772]],\n",
       "  \n",
       "         [[0.18317215, 0.16979223, 0.16707142],\n",
       "          [0.17472   , 0.16296703, 0.16287386],\n",
       "          [0.16769558, 0.15448968, 0.1573315 ],\n",
       "          ...,\n",
       "          [0.2278513 , 0.19484553, 0.1642121 ],\n",
       "          [0.22307283, 0.19272116, 0.1681005 ],\n",
       "          [0.22479358, 0.2004072 , 0.1781072 ]]], dtype=float32),\n",
       "  array([[[0.2828955 , 0.25612095, 0.23157935],\n",
       "          [0.27991867, 0.24696474, 0.22465739],\n",
       "          [0.29094842, 0.24790862, 0.2213197 ],\n",
       "          ...,\n",
       "          [0.255206  , 0.2324808 , 0.21716219],\n",
       "          [0.25407645, 0.2342723 , 0.21967223],\n",
       "          [0.26527452, 0.24599163, 0.23232476]],\n",
       "  \n",
       "         [[0.27438554, 0.24248978, 0.21679692],\n",
       "          [0.27393645, 0.23338678, 0.20582579],\n",
       "          [0.2850867 , 0.23141918, 0.20222928],\n",
       "          ...,\n",
       "          [0.2561827 , 0.22784452, 0.21158463],\n",
       "          [0.24704094, 0.22570807, 0.20974217],\n",
       "          [0.26335925, 0.24568288, 0.22715046]],\n",
       "  \n",
       "         [[0.2679377 , 0.23127334, 0.20185827],\n",
       "          [0.26569104, 0.22256126, 0.1892932 ],\n",
       "          [0.2655756 , 0.2211177 , 0.19013244],\n",
       "          ...,\n",
       "          [0.25334474, 0.22986951, 0.21100163],\n",
       "          [0.2399678 , 0.21981573, 0.19809978],\n",
       "          [0.25038412, 0.22970042, 0.20932648]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.16568989, 0.14955719, 0.14542031],\n",
       "          [0.1580778 , 0.14495046, 0.14050643],\n",
       "          [0.15165055, 0.13846593, 0.13679706],\n",
       "          ...,\n",
       "          [0.21193253, 0.17884398, 0.13805784],\n",
       "          [0.20514077, 0.1711352 , 0.13356753],\n",
       "          [0.20135875, 0.17338127, 0.14550026]],\n",
       "  \n",
       "         [[0.16499764, 0.15469524, 0.1560201 ],\n",
       "          [0.15401785, 0.14287816, 0.14403802],\n",
       "          [0.15234144, 0.14282362, 0.13919336],\n",
       "          ...,\n",
       "          [0.20192772, 0.16543266, 0.13480006],\n",
       "          [0.1991502 , 0.16782133, 0.1414213 ],\n",
       "          [0.20219691, 0.17500275, 0.15405305]],\n",
       "  \n",
       "         [[0.17081214, 0.15852432, 0.15673426],\n",
       "          [0.1624337 , 0.15183584, 0.15269963],\n",
       "          [0.15515777, 0.14325382, 0.1470536 ],\n",
       "          ...,\n",
       "          [0.2101975 , 0.1793379 , 0.15056668],\n",
       "          [0.20614125, 0.17761771, 0.1547349 ],\n",
       "          [0.20840952, 0.18565318, 0.16489549]]], dtype=float32)],\n",
       " array([1., 1., 1., 1., 1.])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_noise_1d(test, cvae_labels[2], ranges, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Widget ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_to_img(idx):\n",
    "    grid_data = add_noise(mu[idx], cvae_labels[idx], np.linspace(-3, 3, 10), 1)\n",
    "    [row, col], img, prob, loss_normed = grid_data[0]\n",
    "    img = img.detach().cpu().numpy()\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(x):\n",
    "    x_scaled = np.uint8(255 * (x - x.min()) / x.ptp())\n",
    "    return Image.fromarray(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b73208ade849c8a9c129aeb145c194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christoph/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ae2d39c31749e39266867552910acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=49, description='range_step', max=99), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = widgets.FloatText()\n",
    "display(a)\n",
    "\n",
    "def display_sequence(images, probs):\n",
    "    def _show(range_step=(0, len(images)-1)):\n",
    "        a.value = probs[range_step]\n",
    "        return display_image(images[range_step])\n",
    "    return interact(_show)\n",
    "\n",
    "x = torch.Tensor(embs[0]).to(DEVICE)\n",
    "images, probs = add_noise_1d(x, cvae_labels[7], np.linspace(-3, 3, 100), 1)\n",
    "    \n",
    "prob = probs[0]    \n",
    "\n",
    "display_sequence(images, probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim-0: dunkel-hell\n",
    "# dim-1: klein-groß\n",
    "# dim-2: Kontrast\n",
    "# dim-3: Ausleuchtung\n",
    "# dim-4: Winkel(?) und Ausleuchtung"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
